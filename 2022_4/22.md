# 4/22

## atcoder

幅優先の実装

割り算の高速化

## kaggle

Boosting

バギングでは、個別にデータセットとモデルが作られていたが、Boostingでは、逐次的に生成される。

オリジナルの学習データに対して、モデルを生成し、そのモデルが予測できたデータとできなかったデータを選り分ける。
次のモデルでは、予測から外れたデータを重視できるように学習データを作成する。これを繰り返してモデルを複数作成し、最終的にそれらの予測を組み合わせる。

```
# インポート
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

# housingデータを読み込み
boston = load_boston()
X_train, X_test, y_train, y_test = train_test_split(
    boston.data, boston.target, random_state=66)

# 決定木とAdaBoostRegressorのパラメータ設定
models = {
    'tree': DecisionTreeRegressor(random_state=0),
    'AdaBoost': AdaBoostRegressor(DecisionTreeRegressor(), random_state=0) 
}

# モデル構築
scores = {}
for model_name, model in models.items():
    model.fit(X_train, y_train)
    scores[(model_name, 'train_score')] = model.score(X_train, y_train)
    scores[(model_name, 'test_score')] = model.score(X_test, y_test)

# 結果を表示
pd.Series(scores).unstack()
```

## python Udemy

```
import asyncio

loop = asyncio.get_event_loop()

async def worker1(lock):
    print('worker1 start')
    async with lock:
        print('worker1 got lock')
        await asyncio.sleep(3)
    print('worker1 end')

@asyncio.coroutine
def worker2(lock):
    print('worker2 start')
    with (yield from lock):
        print('worker2 got lock')
        yield from asyncio.sleep(3)
    print('worker2 end')

async def worker3(lock):
    print('worker3 start')
    with await lock:
        print('worker3 got lock')
        await asyncio.sleep(3)
    print('worker3 end')

lock = asyncio.Lock()
loop.run_until_complete(asyncio.wait([
    worker1(lock), worker2(lock), worker3(lock)
    ]))
loop.close()
```

## 統計
指数分布の期待値、分散をモーメント母関数を用いて導出

## その他

Today, I studied about Linux all the day.

When I study it, I write the learning memo by Markdown.

But if I constrain writing memo, It takes many times.

- DeepL

I spent all day today studying Linux.

When I study, I use Markdown to summarize the content and make notes.

However, if I concentrate too much on taking notes, it takes a long time.
