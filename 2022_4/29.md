# 4/29

## atcoder

ピラミッド

年齢の最大値　グラフ化

## kaggle

複数モデルの比較

```
# 必要なライブラリ等のインポート
from sklearn.datasets import load_breast_cancer
from sklearn.tree import  DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor


# 乳がんのデータを読み込み
cancer = load_breast_cancer()

models ={
# 決定木クラスの初期化

    'RandomForest': RandomForestRegressor(random_state=0),
    'GradientBoost': GradientBoostingRegressor(random_state=0, learning_rate=0.3, n_estimators=10),
    'Tree': DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0),
    'LinearR': LogisticRegression(random_state=0),
    'SVM': SVC(random_state=0),
    'k-nn': KNeighborsClassifier(n_neighbors=5),
    
}

# モデル構築
scores = {}
for model_name, model in models.items():
    # k分割交差検証の実行
    score = cross_val_score(model, cancer.data, cancer.target, cv=5)
    print(f'{model_name} \t {score}')
    scores[model_name] = score
    
    # model.fit(train_x, train_y)
    # scores[(model_name, 'train_score')] = model.score(train_x, train_y)
    # scores[(model_name, 'test_score')] = model.score(test_x, test_y)
# 結果を表示
print("result")

for n, s in scores.items():
    print("Cross validation scores {}: {:.3f}+-{:.3f}".format(n, s.mean(), s.std()))

```

### 総合問題9-1 教師あり学習の用語(2)

- 過学習
 
 過学習は、オーバーフィッティング、過剰学習とも表現される。機械学習のモデルに訓練用のデータが当てはまりすぎて、未知のデータで良い結果が得られなくなる現象である。
- ホールドアウト法

 機械学習モデルの学習時に、データを訓練用とテスト用の2つにランダムに分割し、訓練用で学習を行い、テスト用で検証を行う手法のことである。
 教師あり学習モデルには高い汎用性が求められる。学習データを既知のデータ、テストデータを未知のデータとみなすことで、その未知のデータにおける精度を検証するというシンプルな手法である。データが大量にある場合には有効な手法だが、データが少ない場合には主に2つの問題が生じる。1つ目は一部のデータに対する過学習である。ランダムに分割したとき、たまたまそのときのテストデータに対して良い結果が得られる可能性がある。もう一つは学習が十分に行われないことである。限られたデータセットを学習用と、テスト用に分割するため学習用のデータが十分に得られず、学習があまり進まなくなる。
- 交差検証法

 限られたデータセットを最大限に活用し、学習するための手法である。交差検証法の代表的手法が、k分割交差検証法(k-fold cross validation)である。この手法では、データセットをランダムにk個に分割する。分割したうちのk-1個を学習用データセット、残りの1個を検証用として使用する。分割したデータセットをテスト用と学習用のデータに分ける組み合わせの数はk通りである。k通りの組み合わせのそれぞれで学習と検証を繰り返し、評価値を取得する。
 k通りの検証データを使用することができるのでたまたま、ある検証データで良い結果が得られるという現象を防ぐことができる。また、ホールドアウト法と比べてすべてのデータを一通り学習に使用できるのでデータを最大限活かすことができている。
 k-fold cross validation の派生として１個抜き交差検証(leave-one-out)がある。k-fold cross validationのk個の分割数をデータ数と同数に設定する手法である。組み合わせがデータの総数と同じになるので、データ数がかなり少ないときに有効である。
- グリッドサーチ

 機械学習モデルのそもそもの汎化性能を向上させる手法である。各アルゴリズムには固有のパラメータが存在し、これらはハイパーパラメータと呼ばれている。ハイパーパラメータは、学習時にモデルによって決定される値ではなく、人間が調整するモデルの性能を決定づけるパラメータのことである。選択したハイパーパラメータのすべての組み合わせについて交差検証を行い、最も性能の高いパラメータの組み合わせを選択する。
 グリッドサーチのときのハイパーパラメータの値は対数スケールで変化させるのが一般的。sklearn のライブラリにはこれらの処理を簡単に行えるモジュールが用意されており、検証も交差検証ではなくk分割交差検証法を使用してくれる。

- 特徴量

 特徴量は、モデルの出力を特徴づけるものである。説明変数とも言われる。

- 特徴抽出
 モデルの過学習が疑われるとき、特徴量を減らす次元削減が有効な手段として挙げられる。次元削減の方法として特徴選択と特徴抽出がある。特徴選択は出力に影響が大きそうな特徴量を選択して使用する手法、特徴抽出は元の特徴空間軸を別の空間軸に変換する手法である。

- 混合行列
 予測精度を図るための指標の一つ。分類モデルの評価を考える際の基本となる行列。モデルの予測値と観測値の関係を表す。具体的には4つの区分を持ち、予測値の正例(positive)と負例(negative)が列に、観測値の正例、負例が行に並んでいる。

- ROC曲線
 ROC曲線は、縦軸に真陽性率、横軸に偽陽性率の値をプロットした曲線。真陽性率は、実際の正例のうちどれだけを正例と予測できたかの割合、偽陽性率は、実際は負例のうち誤って正例と予測してしまった割合を表す。予測確率を予測ラベルに変換する際のしきい値を0から1に変化させて、真陽性率と偽陽性率の関係をプロットすることでROC曲線を描く。

- 適合率
 適合率は、予測した値のうち実際どれだけの値があっているかの割合。異常検知のアラートシステムなどで重視される。
- 再現率
 再現率は、実際のあるクラスのうちどれだけ正しいクラスを予測することができたかの割合。病気の診断システムなどで重視される。
- 正解率
 予測した値のうち、正解したものの割合。
- F1スコア
 適合率と再現率の調和平均。適合率を優先すべきか、再現率を優先すべきか決まっていないときにモデルを総合的に評価するのに利用される。
- 真陽性率（True Positive Rate）
 実際の正例のうち、どれだけ正例と予測できたかの割合。
- 偽陽性率（False Positive Rate）
 実際の負例のうち、誤って正例と予測されてしまった割合。
- AUC
 AUC(Area under the curbe)は名前の通りROC曲線の下の部分の面積である。AUCの値は0から1で変化し、最適理想曲線で1.0, 予測確率がランダムのときには0.5となる。
- ブートストラップ法
 元の学習データ（n行）からランダムにn行のデータを復元抽出（重複を許して抽出)することで新しい学習データを作成することを繰り返す手法のこと。
- アンサンブル学習
 アンサンブル学習では学習データを複数用意するのではなく、モデルを複数用意する。それぞれのモデルで得られた予測値を集約することで最終的な出力とする。
- バギング
 バギングは元の学習データ(n行）から重複を許してn行データを抽出する(復元抽出)。この手法で新しい学習データを作成することを繰り返し、それぞれの学習データセットでモデルを学習する。それぞれのモデルでの出力を集約することで予測値を出す。集約する手法は分類タスクであれば最頻値、線形予測であれば平均値などがあげられる。元の学習データと少しづつ異なるデータで学習することができるので汎化性能を向上させる可能性がある。
- ブースティング
 バギングと言われる手法では、本の学習データを復元抽出し、それぞれのデータに対して個別にモデルを学習させていたが、ブートストラップ法ではモデルも逐次作成、適用する手法である。具体的には、まずはじめに元の学習データに対してモデルを学習させる。この学習によって得られた予測値と合致した学習データと外れた学習データを把握する。次の学習データは外れた学習データが重視されるように作成され、そのデータを使ってモデルを学習する。この操作を繰り返す過程でモデルも逐次複数作成される。最後にこれらのモデルの予測値を集約することで最終的な予測値とする。このブースティングの手法はunderfittingのときに有効であると言われている。
- ランダムフォレスト
 分類木を多数集めて、それらの結果を集約することで最終的な出力とする手法。たくさんの分類木を作成するが、似たような分類機が多数あっても意味が無い。そこで各決定木をそれぞれ異なるデータセットで作成、もしくは異なる説明変数を分割候補として作成する。それぞれ異なるデータセットを作成するときはブートストラップサンプリングでデータセットを作成する。異なる説明変数を分割候補として使用する場合は訓練データの説明変数のうち、K個をランダムに選択し、そのK個の中で最もうまく分割できる変数で決定木を分割する。Kは最初に決定するパラメーター。
 
## 統計
畳み込み積分で確率密度の変換を計算するやつ。

## Udemy algorithm

bubble sort
boto sort
    
## dev app
golang 環境設定

## その他

Today is the first day of the GW.

I started to sutudy Go lang for block chain.

Tommorw my family and I go to arts musiam..

- DeepL

Today was the first day of GW

I started learning Go language for blockchain

Tomorrow I am going to a museum with my family.

    
    
    
    
    
    
    
    
    
    
