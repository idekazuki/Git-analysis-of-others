# 4/21

## atcoder

幅探索、深さ探索

## kaggle

バギング

元のデータからランダムに復元抽出して弱学習機をたくさん作って最終的な学習機を構築

```
# インポート
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# 乳がんのデータを読み込み
cancer = load_breast_cancer()

# 訓練データとテストデータに分ける
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, stratify = cancer.target, random_state=66)

# k-NNモデルとそのバギングの設定
models = {
    'kNN': KNeighborsClassifier(),
    'bagging': BaggingClassifier(KNeighborsClassifier(), n_estimators=100, random_state=0) 
}

# モデル構築
scores = {}
for model_name, model in models.items():
    model.fit(X_train, y_train)
    scores[(model_name, 'train_score')] = model.score(X_train, y_train)
    scores[(model_name, 'test_score')] = model.score(X_test, y_test)

# 結果を表示
pd.Series(scores).unstack(

```
## python Udemy

```
def s_hello():
    yield 'hello 1'
    yield 'hello 2'
    yield 'hello 3'
    return 'done'

def g_hello():
    while True:
        r = yield from s_hello()
        yield r

g = g_hello()

print(next(g))
print(next(g))
print(next(g))
print(next(g))
print(next(g))
print(next(g))
print(next(g))
print(next(g))

```
非同期
```
import asyncio

loop = asyncio.get_event_loop()

# before python3.5
# @asyncio.coroutine
# def worker():
#     print('start')
# #you have to use yield. if you use sleep, no async.
#     yield from asyncio.sleep(2)
#     print('stop')

# if __name__ == '__main__':
#     loop.run_until_complete(asyncio.wait([worker(), worker()]))
#     loop.close()

#after python3.5

async def worker():
    print('start')
    await asyncio.sleep(2)
    print('stop')

if __name__ == '__main__':
    loop.run_until_complete(asyncio.wait([worker(), worker()]))
    loop.close()



```

## 統計

連続関数の確率密度関数

## dev app
option のあれこれ、tailコマンドの実装。リングバッファ構造を使う。

## その他

Today Ohtani has done perfect pitching.

I bought a book of AI written by CEO of PFN.

- DeepL

Ohtani accomplished a perfect pitching perfomance today.

I bought a book written by the CEO of PEN.

